{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "X28zqoct9wvx"
      },
      "outputs": [],
      "source": [
        "import gzip\n",
        "import gensim \n",
        "import logging\n",
        "\n",
        "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y1itQb_kHZKq",
        "outputId": "12448293-4b89-4534-da8a-266ef7e23a15"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (4.6.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown) (3.12.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown) (2.27.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from gdown) (1.16.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown) (4.65.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown) (4.11.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown) (2.4.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.4)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.7.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install gdown"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gmT4xRWDHZKs",
        "outputId": "374ed35e-ee14-4739-94d2-cbf73a5184bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 1662.8/1662.8MB downloaded\n"
          ]
        }
      ],
      "source": [
        "from gensim.models import KeyedVectors\n",
        "\n",
        "# Download the pre-trained word2vec model from Google's Word2Vec\n",
        "word2vec_file_path = './word2vec_file.bin'\n",
        "\n",
        "# Downloading the model (example for a 300-dimensional model)\n",
        "import gensim.downloader as api\n",
        "model = api.load('word2vec-google-news-300')\n",
        "\n",
        "# Save the model in the binary format\n",
        "model.save_word2vec_format(word2vec_file_path, binary=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "iPocFyN-1UDo"
      },
      "outputs": [],
      "source": [
        "from gensim.models import KeyedVectors\n",
        "\n",
        "def import_word2vec_embeddings(file_path):\n",
        "    # Load the pre-trained word2vec model\n",
        "    model = KeyedVectors.load_word2vec_format(file_path, binary=True)\n",
        "    \n",
        "    # Create an empty dictionary to store the word embeddings\n",
        "    word_embeddings = {}\n",
        "\n",
        "    # Populate the dictionary with word embeddings\n",
        "    for word in model.key_to_index:\n",
        "        word_embeddings[word] = model.get_vector(word)\n",
        "    \n",
        "    return word_embeddings\n",
        "\n",
        "# Provide the file path to your word2vec file\n",
        "word2vec_file_path = './word2vec_file.bin'\n",
        "\n",
        "# Call the function to import word2vec embeddings into a dictionary\n",
        "word_embeddings = import_word2vec_embeddings(word2vec_file_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CNOsq_5rHZKu",
        "outputId": "7cd5ceda-3b2d-45c4-ca38-85e113771d7d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3000000\n"
          ]
        }
      ],
      "source": [
        "print(len(word_embeddings.keys()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "-SVZevuYHZKw"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "def pick_random_pairs(dictionary, num_pairs):\n",
        "    keys = list(dictionary.keys())\n",
        "    random.shuffle(keys)\n",
        "    random_pairs = {}\n",
        "    for key in keys[:num_pairs]:\n",
        "        random_pairs[key] = dictionary[key]\n",
        "    return random_pairs\n",
        "\n",
        "random_embeddings = pick_random_pairs(word_embeddings,1000000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IQIJwSJy1UDu",
        "outputId": "1cfcaaef-1b43-48ce-f9a6-59445ae3b095"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1000000\n"
          ]
        }
      ],
      "source": [
        "print(len(random_embeddings.keys()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "flXXA-L9GSGX"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.preprocessing import normalize\n",
        "\n",
        "def normalize_word_embeddings(word_embeddings):\n",
        "    # Extract the word vectors and store them in a numpy array\n",
        "    embeddings = np.array(list(word_embeddings.values()))\n",
        "\n",
        "    # Normalize the word embeddings\n",
        "    normalized_embeddings = normalize(embeddings)\n",
        "\n",
        "    # Update the normalized embeddings back in the dictionary\n",
        "    for i, word in enumerate(word_embeddings.keys()):\n",
        "        word_embeddings[word] = normalized_embeddings[i]\n",
        "\n",
        "    return word_embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Bd9WO6vE1UDw"
      },
      "outputs": [],
      "source": [
        "# Call the function to get normalized word embeddings\n",
        "normalized_embeddings = normalize_word_embeddings(random_embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "QeitKg2FjfUB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9677b34-f2c3-44f9-f324-bf9682620f86"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting faiss-gpu\n",
            "  Downloading faiss_gpu-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (85.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.5/85.5 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-gpu\n",
            "Successfully installed faiss-gpu-1.7.2\n"
          ]
        }
      ],
      "source": [
        "!pip install faiss-gpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "8Qmb3UMi1UDx"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import faiss\n",
        "\n",
        "'''\n",
        "num_clusters = 256  \n",
        "quantizer = faiss.IndexFlatL2(embedding_vectors.shape[1])\n",
        "index = faiss.IndexIVFFlat(quantizer, embedding_vectors.shape[1], num_clusters)\n",
        "index.train(embedding_vectors)\n",
        "index.add(embedding_vectors)\n",
        "_, similar_indices = index.search(embedding_vectors, num_similar)\n",
        "\n",
        "'''\n",
        "\n",
        "def calculate_fractal_value(embeddings, box_size, k):\n",
        "    \n",
        "    embedding_vectors = np.array(list(embeddings.values()))\n",
        "    \n",
        "    # Initialize Faiss index\n",
        "    embedding_dim = embedding_vectors.shape[1]\n",
        "    index = faiss.IndexFlatL2(embedding_dim)\n",
        "\n",
        "    # Add embeddings to the Faiss index\n",
        "    index.add(embedding_vectors)\n",
        "\n",
        "    # Search for the nearest neighbors of all vectors\n",
        "    neighbor_distances , neighbor_indices = index.search(embedding_vectors, k)\n",
        "    \n",
        "    # Calculating similarity values using the neighbor_distances and updating it.\n",
        "    for i in range(neighbor_distances.shape[0]):\n",
        "        for j in range(neighbor_distances.shape[1]):\n",
        "            neighbor_distances[i][j] = 1/(1+neighbor_distances[i][j])\n",
        "    \n",
        "    print(neighbor_distances)\n",
        "\n",
        "    # Apply box counting algorithm for fractal value calculation\n",
        "    num_boxes = 0\n",
        "    num_filled_boxes = 0\n",
        "\n",
        "    # Iterate over the similarity scores in chunks of box_size\n",
        "    for i in range(0, embedding_vectors.shape[0], box_size):\n",
        "        box_scores = neighbor_distances[i:i+box_size, :]\n",
        "\n",
        "        for i in range(box_scores.shape[0]):\n",
        "            for j in range(box_scores.shape[1]):\n",
        "                if(box_scores[i][j]>0.5):\n",
        "                    num_filled_boxes += 1\n",
        "\n",
        "        num_boxes+=1\n",
        "        \n",
        "    print(num_filled_boxes,num_boxes)\n",
        "    fractal_dimension = np.log(num_filled_boxes) / np.log(num_boxes)\n",
        "    return fractal_dimension"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "MDCGF7gT1UDy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1187edc5-a7b3-4fb8-b278-7f5586af5f39"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.9999999  0.53470135 0.52227837 ... 0.45049554 0.45048887 0.45048872]\n",
            " [1.         0.547726   0.5393408  ... 0.4523802  0.45237556 0.45236173]\n",
            " [1.         0.7051065  0.68094784 ... 0.5217019  0.5216767  0.52166843]\n",
            " ...\n",
            " [0.9999999  0.65995324 0.6590021  ... 0.52847683 0.5284419  0.52831197]\n",
            " [0.99999976 0.5050519  0.5028653  ... 0.45966485 0.4596595  0.45965248]\n",
            " [0.99999976 0.6395914  0.62621284 ... 0.5427284  0.54272753 0.5426817 ]]\n",
            "442208944 100000\n",
            "Fractal Dimension: 1.729125504451146\n",
            "CPU times: user 8h 29min 58s, sys: 42.7 s, total: 8h 30min 40s\n",
            "Wall time: 4h 22min 9s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "fractal_dim = calculate_fractal_value(normalized_embeddings,10,1000)\n",
        "print(\"Fractal Dimension:\", fractal_dim)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}