{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "X28zqoct9wvx"
   },
   "outputs": [],
   "source": [
    "import gzip\n",
    "import gensim \n",
    "import logging\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v6cM9qG99wv-",
    "outputId": "3b235704-4a97-4ebd-836a-d276ed6193db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 23.3.1\n",
      "  latest version: 23.5.0\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "Or to minimize the number of packages updated during conda update use\n",
      "\n",
      "     conda install conda=23.5.0\n",
      "\n",
      "\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /Users/akallaku/anaconda3\n",
      "\n",
      "  added / updated specs:\n",
      "    - fasttext\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    ca-certificates-2023.5.7   |       h8857fd0_0         145 KB  conda-forge\n",
      "    certifi-2023.5.7           |     pyhd8ed1ab_0         149 KB  conda-forge\n",
      "    fasttext-0.9.2             |  py310ha23aa8a_5         445 KB  conda-forge\n",
      "    openssl-1.1.1u             |       h8a1eda9_0         1.7 MB  conda-forge\n",
      "    pybind11-2.10.4            |  py310ha23aa8a_0         176 KB  conda-forge\n",
      "    pybind11-global-2.10.4     |  py310ha23aa8a_0         165 KB  conda-forge\n",
      "    python_abi-3.10            |          2_cp310           4 KB  conda-forge\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:         2.7 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  fasttext           conda-forge/osx-64::fasttext-0.9.2-py310ha23aa8a_5 \n",
      "  pybind11           conda-forge/osx-64::pybind11-2.10.4-py310ha23aa8a_0 \n",
      "  pybind11-global    conda-forge/osx-64::pybind11-global-2.10.4-py310ha23aa8a_0 \n",
      "  python_abi         conda-forge/osx-64::python_abi-3.10-2_cp310 \n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  ca-certificates    pkgs/main::ca-certificates-2023.01.10~ --> conda-forge::ca-certificates-2023.5.7-h8857fd0_0 \n",
      "  certifi            pkgs/main/osx-64::certifi-2022.12.7-p~ --> conda-forge/noarch::certifi-2023.5.7-pyhd8ed1ab_0 \n",
      "  openssl              pkgs/main::openssl-1.1.1t-hca72f7f_0 --> conda-forge::openssl-1.1.1u-h8a1eda9_0 \n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "pybind11-global-2.10 | 165 KB    |                                       |   0% \n",
      "openssl-1.1.1u       | 1.7 MB    |                                       |   0% \u001b[A\n",
      "\n",
      "certifi-2023.5.7     | 149 KB    |                                       |   0% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "python_abi-3.10      | 4 KB      |                                       |   0% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "fasttext-0.9.2       | 445 KB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "pybind11-2.10.4      | 176 KB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ca-certificates-2023 | 145 KB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "pybind11-global-2.10 | 165 KB    | ###5                                  |  10% \u001b[A\n",
      "\n",
      "certifi-2023.5.7     | 149 KB    | ###9                                  |  11% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "python_abi-3.10      | 4 KB      | ##################################### | 100% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "python_abi-3.10      | 4 KB      | ##################################### | 100% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "pybind11-2.10.4      | 176 KB    | ###3                                  |   9% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "openssl-1.1.1u       | 1.7 MB    | ###########5                          |  31% \u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ca-certificates-2023 | 145 KB    | ####                                  |  11% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "fasttext-0.9.2       | 445 KB    | #3                                    |   4% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "certifi-2023.5.7     | 149 KB    | ##################################### | 100% \u001b[A\u001b[A\n",
      "\n",
      "certifi-2023.5.7     | 149 KB    | ##################################### | 100% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ca-certificates-2023 | 145 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ca-certificates-2023 | 145 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "fasttext-0.9.2       | 445 KB    | ###################################8  |  97% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "pybind11-2.10.4      | 176 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "pybind11-global-2.10 | 165 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "openssl-1.1.1u       | 1.7 MB    | ##################################### | 100% \u001b[A\n",
      "openssl-1.1.1u       | 1.7 MB    | ##################################### | 100% \u001b[A\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda install -c conda-forge fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y1itQb_kHZKq",
    "outputId": "f1b5c54f-3680-4e33-c373-3f9ad5902e5c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gdown\n",
      "  Downloading gdown-4.7.1-py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: six in /Users/akallaku/anaconda3/lib/python3.10/site-packages (from gdown) (1.16.0)\n",
      "Requirement already satisfied: filelock in /Users/akallaku/anaconda3/lib/python3.10/site-packages (from gdown) (3.9.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /Users/akallaku/anaconda3/lib/python3.10/site-packages (from gdown) (4.11.1)\n",
      "Requirement already satisfied: tqdm in /Users/akallaku/anaconda3/lib/python3.10/site-packages (from gdown) (4.64.1)\n",
      "Requirement already satisfied: requests[socks] in /Users/akallaku/anaconda3/lib/python3.10/site-packages (from gdown) (2.28.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/akallaku/anaconda3/lib/python3.10/site-packages (from beautifulsoup4->gdown) (2.3.2.post1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/akallaku/anaconda3/lib/python3.10/site-packages (from requests[socks]->gdown) (1.26.14)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/akallaku/anaconda3/lib/python3.10/site-packages (from requests[socks]->gdown) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/akallaku/anaconda3/lib/python3.10/site-packages (from requests[socks]->gdown) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/akallaku/anaconda3/lib/python3.10/site-packages (from requests[socks]->gdown) (2023.5.7)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /Users/akallaku/anaconda3/lib/python3.10/site-packages (from requests[socks]->gdown) (1.7.1)\n",
      "Installing collected packages: gdown\n",
      "Successfully installed gdown-4.7.1\n"
     ]
    }
   ],
   "source": [
    "!pip install gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HRnK2mxcHZKr",
    "outputId": "10351240-7156-4cf2-ec41-533cbe1f16b5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.en.300.bin.gz\n",
      "To: /Users/akallaku/Downloads/cc.en.300.bin.gz\n",
      "100%|██████████████████████████████████████| 4.50G/4.50G [01:42<00:00, 44.1MB/s]\n"
     ]
    }
   ],
   "source": [
    "# Download the FastText model file if it doesn't exist\n",
    "import os\n",
    "import gdown\n",
    "if not os.path.exists('cc.en.300.bin'):\n",
    "        url = 'https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.en.300.bin.gz'\n",
    "        output = 'cc.en.300.bin.gz'\n",
    "        gdown.download(url, output, quiet=False)\n",
    "\n",
    "        with gzip.open(output, 'rb') as f_in:\n",
    "            with open('cc.en.300.bin', 'wb') as f_out:\n",
    "                f_out.write(f_in.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gmT4xRWDHZKs",
    "outputId": "b2a76d9d-660e-4251-c12c-b1b61b7310e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "import fasttext.util\n",
    "\n",
    "model_path = 'cc.en.300.bin'\n",
    "\n",
    "model = fasttext.load_model(model_path)\n",
    "\n",
    "# Get the word embeddings\n",
    "embeddings = model.get_input_matrix()\n",
    "\n",
    "# Create a dictionary to store the word embeddings\n",
    "documents = []\n",
    "word_embeddings = {}\n",
    "\n",
    "# Populate the dictionary with word embeddings\n",
    "for word, vector in zip(model.get_words(), embeddings):\n",
    "    word_embeddings[word] = vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CNOsq_5rHZKu",
    "outputId": "a8e70e43-dee5-40c2-bf93-54ac86f20487"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000000\n"
     ]
    }
   ],
   "source": [
    "print(len(word_embeddings.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "-SVZevuYHZKw"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def pick_random_pairs(dictionary, num_pairs):\n",
    "    keys = list(dictionary.keys())\n",
    "    random.shuffle(keys)\n",
    "    random_pairs = {}\n",
    "    for key in keys[:num_pairs]:\n",
    "        random_pairs[key] = dictionary[key]\n",
    "    return random_pairs\n",
    "\n",
    "random_embeddings = pick_random_pairs(word_embeddings,1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rJs8ecLWNzgW",
    "outputId": "4cfa8221-e0e4-4d46-915c-d28080f168f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000000\n"
     ]
    }
   ],
   "source": [
    "print(len(random_embeddings.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "flXXA-L9GSGX"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "def normalize_word_embeddings(word_embeddings):\n",
    "    # Extract the word vectors and store them in a numpy array\n",
    "    embeddings = np.array(list(word_embeddings.values()))\n",
    "\n",
    "    # Normalize the word embeddings\n",
    "    normalized_embeddings = normalize(embeddings)\n",
    "\n",
    "    # Update the normalized embeddings back in the dictionary\n",
    "    for i, word in enumerate(word_embeddings.keys()):\n",
    "        word_embeddings[word] = normalized_embeddings[i]\n",
    "\n",
    "    return word_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "O8BHr5yyNzgY"
   },
   "outputs": [],
   "source": [
    "# Call the function to get normalized word embeddings\n",
    "normalized_embeddings = normalize_word_embeddings(random_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QeitKg2FjfUB",
    "outputId": "d646be92-67ab-4703-b00e-3ecba583f459"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 23.3.1\n",
      "  latest version: 23.5.0\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "Or to minimize the number of packages updated during conda update use\n",
      "\n",
      "     conda install conda=23.5.0\n",
      "\n",
      "\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda install -c conda-forge faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "G3qfNg9ONzga"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import faiss\n",
    "\n",
    "'''\n",
    "num_clusters = 256  \n",
    "quantizer = faiss.IndexFlatL2(embedding_vectors.shape[1])\n",
    "index = faiss.IndexIVFFlat(quantizer, embedding_vectors.shape[1], num_clusters)\n",
    "index.train(embedding_vectors)\n",
    "index.add(embedding_vectors)\n",
    "_, similar_indices = index.search(embedding_vectors, num_similar)\n",
    "\n",
    "'''\n",
    "\n",
    "def calculate_fractal_value(embeddings, box_size, k):\n",
    "    \n",
    "    embedding_vectors = np.array(list(embeddings.values()))\n",
    "    \n",
    "    # Initialize Faiss index\n",
    "    embedding_dim = embedding_vectors.shape[1]\n",
    "    index = faiss.IndexFlatL2(embedding_dim)\n",
    "\n",
    "    # Add embeddings to the Faiss index\n",
    "    index.add(embedding_vectors)\n",
    "\n",
    "    # Search for the nearest neighbors of all vectors\n",
    "    neighbor_distances , neighbor_indices = index.search(embedding_vectors, k)\n",
    "    \n",
    "    # Calculating similarity values using the neighbor_distances and updating it.\n",
    "    for i in range(neighbor_distances.shape[0]):\n",
    "        for j in range(neighbor_distances.shape[1]):\n",
    "            neighbor_distances[i][j] = 1/(1+neighbor_distances[i][j])\n",
    "    \n",
    "    print(neighbor_distances)\n",
    "\n",
    "    #Resultant fractal dimension array\n",
    "    fractal_dimensions = []\n",
    "\n",
    "    for i in range(embedding_vectors.shape[0]):\n",
    "        num_boxes = 0\n",
    "        num_filled_boxes = 0\n",
    "\n",
    "        # Iterate over the similarity scores of each vector in chunks of box_size\n",
    "        for j in range(0,neighbor_distances.shape[1],box_size):\n",
    "            box_scores = neighbor_distances[i,j:j+box_size]\n",
    "            \n",
    "            for score in box_scores:\n",
    "                if(score>0.5):\n",
    "                    num_filled_boxes += 1\n",
    "\n",
    "            num_boxes+=1\n",
    "\n",
    "        fractal_dimension = np.log(num_filled_boxes) / np.log(num_boxes)\n",
    "        fractal_dimensions.append(fractal_dimension)\n",
    "\n",
    "    return fractal_dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "Y03oXI0RNzga"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.55930865 0.5567445  ... 0.49860162 0.49857584 0.49856958]\n",
      " [1.         0.60488784 0.597303   ... 0.49126327 0.4912624  0.49124846]\n",
      " [0.9999995  0.67742634 0.66604745 ... 0.54839164 0.5483559  0.5483506 ]\n",
      " ...\n",
      " [1.         0.6356718  0.58729595 ... 0.47331423 0.4732174  0.4732162 ]\n",
      " [1.         0.8936764  0.86792403 ... 0.55056363 0.5505435  0.5505313 ]\n",
      " [1.         0.71451384 0.6806422  ... 0.55842215 0.55840087 0.5583906 ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "fractal_dimensions = calculate_fractal_value(normalized_embeddings,10,1000)\n",
    "print(\"Fractal Dimension:\", fractal_dimensions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Fractal_dimension_polysemous_words_1M_1000_10', 'w') as f:\n",
    "    for dimension in fractal_dimensions:\n",
    "        f.write(str(dimension) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000000\n"
     ]
    }
   ],
   "source": [
    "print(len(open('Fractal_dimension_polysemous_words_1M_1000_10', 'r').readlines()))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
