{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "X28zqoct9wvx"
   },
   "outputs": [],
   "source": [
    "import gzip\n",
    "import gensim \n",
    "import logging\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v6cM9qG99wv-",
    "outputId": "3b235704-4a97-4ebd-836a-d276ed6193db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving notices: ...working... done\n",
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 23.3.1\n",
      "  latest version: 23.5.0\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "Or to minimize the number of packages updated during conda update use\n",
      "\n",
      "     conda install conda=23.5.0\n",
      "\n",
      "\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda install -c conda-forge fasttext\n",
    "#use (!pip install fasttext) with collab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y1itQb_kHZKq",
    "outputId": "f1b5c54f-3680-4e33-c373-3f9ad5902e5c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gdown in /Users/akallaku/anaconda3/lib/python3.10/site-packages (4.7.1)\n",
      "Requirement already satisfied: tqdm in /Users/akallaku/anaconda3/lib/python3.10/site-packages (from gdown) (4.64.1)\n",
      "Requirement already satisfied: six in /Users/akallaku/anaconda3/lib/python3.10/site-packages (from gdown) (1.16.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /Users/akallaku/anaconda3/lib/python3.10/site-packages (from gdown) (4.11.1)\n",
      "Requirement already satisfied: requests[socks] in /Users/akallaku/anaconda3/lib/python3.10/site-packages (from gdown) (2.28.1)\n",
      "Requirement already satisfied: filelock in /Users/akallaku/anaconda3/lib/python3.10/site-packages (from gdown) (3.9.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/akallaku/anaconda3/lib/python3.10/site-packages (from beautifulsoup4->gdown) (2.3.2.post1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/akallaku/anaconda3/lib/python3.10/site-packages (from requests[socks]->gdown) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/akallaku/anaconda3/lib/python3.10/site-packages (from requests[socks]->gdown) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/akallaku/anaconda3/lib/python3.10/site-packages (from requests[socks]->gdown) (2023.5.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/akallaku/anaconda3/lib/python3.10/site-packages (from requests[socks]->gdown) (1.26.14)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /Users/akallaku/anaconda3/lib/python3.10/site-packages (from requests[socks]->gdown) (1.7.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HRnK2mxcHZKr",
    "outputId": "10351240-7156-4cf2-ec41-533cbe1f16b5"
   },
   "outputs": [],
   "source": [
    "# Download the FastText model file if it doesn't exist\n",
    "import os\n",
    "import gdown\n",
    "if not os.path.exists('cc.en.300.bin'):\n",
    "        url = 'https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.en.300.bin.gz'\n",
    "        output = 'cc.en.300.bin.gz'\n",
    "        gdown.download(url, output, quiet=False)\n",
    "\n",
    "        with gzip.open(output, 'rb') as f_in:\n",
    "            with open('cc.en.300.bin', 'wb') as f_out:\n",
    "                f_out.write(f_in.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gmT4xRWDHZKs",
    "outputId": "b2a76d9d-660e-4251-c12c-b1b61b7310e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "import fasttext.util\n",
    "\n",
    "model_path = 'cc.en.300.bin'\n",
    "\n",
    "model = fasttext.load_model(model_path)\n",
    "\n",
    "# Get the word embeddings\n",
    "embeddings = model.get_input_matrix()\n",
    "\n",
    "# Create a dictionary to store the word embeddings\n",
    "documents = []\n",
    "word_embeddings = {}\n",
    "\n",
    "# Populate the dictionary with word embeddings\n",
    "for word, vector in zip(model.get_words(), embeddings):\n",
    "    word_embeddings[word] = vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CNOsq_5rHZKu",
    "outputId": "a8e70e43-dee5-40c2-bf93-54ac86f20487"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000000\n"
     ]
    }
   ],
   "source": [
    "print(len(word_embeddings.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "-SVZevuYHZKw"
   },
   "outputs": [],
   "source": [
    "def pick_word_embeddings(non_polysemous):\n",
    "    non_polysemous_embeddings = {}\n",
    "    for word in non_polysemous:\n",
    "        if(word in word_embeddings):\n",
    "            non_polysemous_embeddings[word] = word_embeddings[word]\n",
    "    \n",
    "    return non_polysemous_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_polysemous = [\n",
    "    \"banana\", \"guitar\", \"elephant\", \"chair\", \"diamond\", \"piano\", \"lemon\", \"mountain\", \"book\", \"sun\",\n",
    "    \"umbrella\", \"river\", \"butterfly\", \"tree\", \"carrot\", \"moon\", \"flower\", \"ocean\", \"computer\", \"lamp\",\n",
    "    \"coffee\", \"bird\", \"bicycle\", \"cookie\", \"beach\", \"dog\", \"rainbow\", \"camera\", \"island\", \"hat\",\n",
    "    \"turtle\", \"clock\", \"socks\", \"candle\", \"fire\", \"garden\", \"orange\", \"star\", \"bridge\", \"key\",\n",
    "    \"castle\", \"shoe\", \"dolphin\", \"planet\", \"spoon\", \"feather\", \"butter\", \"rocket\", \"pillow\", \"chocolate\",\n",
    "    \"honey\", \"volcano\", \"whale\", \"moonlight\", \"wallet\", \"pineapple\", \"flag\", \"fountain\", \"tiger\", \"map\",\n",
    "    \"sweater\", \"music\", \"airplane\", \"globe\", \"painting\", \"toothbrush\", \"helicopter\", \"snail\", \"statue\", \"cupcake\",\n",
    "    \"seashell\", \"peacock\", \"drum\", \"cloud\", \"cactus\", \"feather\", \"balloon\", \"kangaroo\", \"moonshine\", \"mailbox\",\n",
    "    \"raincoat\", \"pinecone\", \"lighthouse\", \"tornado\", \"volleyball\", \"seagull\", \"whistle\", \"accordion\", \"tadpole\", \"giraffe\",\n",
    "    \"typewriter\", \"caterpillar\", \"chimney\", \"waffle\", \"suitcase\", \"butterfly\", \"dragonfly\", \"toothpaste\", \"saxophone\", \"doorknob\"\n",
    "]\n",
    "\n",
    "non_polysemous_embeddings = pick_word_embeddings(non_polysemous)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rJs8ecLWNzgW",
    "outputId": "4cfa8221-e0e4-4d46-915c-d28080f168f6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(non_polysemous_embeddings.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "flXXA-L9GSGX"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "def normalize_word_embeddings(word_embeddings):\n",
    "    # Extract the word vectors and store them in a numpy array\n",
    "    embeddings = np.array(list(word_embeddings.values()))\n",
    "\n",
    "    # Normalize the word embeddings\n",
    "    normalized_embeddings = normalize(embeddings)\n",
    "\n",
    "    # Update the normalized embeddings back in the dictionary\n",
    "    for i, word in enumerate(word_embeddings.keys()):\n",
    "        word_embeddings[word] = normalized_embeddings[i]\n",
    "\n",
    "    return word_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "O8BHr5yyNzgY"
   },
   "outputs": [],
   "source": [
    "# Call the function to get normalized word embeddings\n",
    "normalized_embeddings = normalize_word_embeddings(non_polysemous_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QeitKg2FjfUB",
    "outputId": "d646be92-67ab-4703-b00e-3ecba583f459"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 23.3.1\n",
      "  latest version: 23.5.0\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "Or to minimize the number of packages updated during conda update use\n",
      "\n",
      "     conda install conda=23.5.0\n",
      "\n",
      "\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda install -c conda-forge faiss\n",
    "#use (!pip install faiss-gpu) with collab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "G3qfNg9ONzga"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import faiss\n",
    "\n",
    "'''\n",
    "num_clusters = 256  \n",
    "quantizer = faiss.IndexFlatL2(embedding_vectors.shape[1])\n",
    "index = faiss.IndexIVFFlat(quantizer, embedding_vectors.shape[1], num_clusters)\n",
    "index.train(embedding_vectors)\n",
    "index.add(embedding_vectors)\n",
    "_, similar_indices = index.search(embedding_vectors, num_similar)\n",
    "\n",
    "'''\n",
    "\n",
    "def calculate_fractal_value(embeddings, box_size, k):\n",
    "    \n",
    "    embedding_vectors = np.array(list(embeddings.values()))\n",
    "    \n",
    "    # Initialize Faiss index\n",
    "    embedding_dim = embedding_vectors.shape[1]\n",
    "    index = faiss.IndexFlatL2(embedding_dim)\n",
    "\n",
    "    # Add embeddings to the Faiss index\n",
    "    index.add(embedding_vectors)\n",
    "\n",
    "    # Search for the nearest neighbors of all vectors\n",
    "    neighbor_distances , neighbor_indices = index.search(embedding_vectors, k)\n",
    "    \n",
    "    # Calculating similarity values using the neighbor_distances and updating it.\n",
    "    for i in range(neighbor_distances.shape[0]):\n",
    "        for j in range(neighbor_distances.shape[1]):\n",
    "            neighbor_distances[i][j] = 1/(1+neighbor_distances[i][j])\n",
    "    \n",
    "    print(neighbor_distances)\n",
    "\n",
    "    #Resultant fractal dimension array\n",
    "    fractal_dimensions = []\n",
    "\n",
    "    for i in range(embedding_vectors.shape[0]):\n",
    "        num_boxes = 0\n",
    "        num_filled_boxes = 0\n",
    "\n",
    "        # Iterate over the similarity scores of each vector in chunks of box_size\n",
    "        for j in range(0,neighbor_distances.shape[1],box_size):\n",
    "            box_scores = neighbor_distances[i,j:j+box_size]\n",
    "            \n",
    "            for score in box_scores:\n",
    "                if(score>0.5):\n",
    "                    num_filled_boxes += 1\n",
    "\n",
    "            num_boxes+=1\n",
    "\n",
    "        fractal_dimension = np.log(num_filled_boxes) / np.log(num_boxes)\n",
    "        fractal_dimensions.append(fractal_dimension)\n",
    "\n",
    "    return fractal_dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "Y03oXI0RNzga"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9999999  0.60603386 0.5211427  0.50815773 0.50703686 0.49982756\n",
      "  0.4698076  0.46579275 0.4645673  0.46301308]\n",
      " [1.         0.6581317  0.65242666 0.56353515 0.52065456 0.4974467\n",
      "  0.45414054 0.43591365 0.4229159  0.4202017 ]\n",
      " [1.         0.6208895  0.57823974 0.52924216 0.52513665 0.4989824\n",
      "  0.47959894 0.47592697 0.4739656  0.4606309 ]\n",
      " [0.99999976 0.47525698 0.47057778 0.4590307  0.44728136 0.4374813\n",
      "  0.42956063 0.4291568  0.4261069  0.42476687]\n",
      " [1.         0.44931605 0.4448735  0.43613252 0.43193793 0.4314114\n",
      "  0.4256567  0.42453325 0.41904935 0.41862467]\n",
      " [1.         0.6581356  0.6581317  0.58750373 0.54582864 0.47780707\n",
      "  0.47352046 0.443944   0.42881244 0.4279795 ]\n",
      " [1.         0.55838406 0.53358525 0.49982756 0.49786347 0.48422334\n",
      "  0.46267027 0.45796233 0.4527005  0.4475706 ]\n",
      " [0.99999976 0.5043197  0.49549836 0.47671738 0.46288696 0.45786965\n",
      "  0.4500409  0.44903585 0.44875526 0.44683307]\n",
      " [1.         0.43504474 0.4242664  0.42384756 0.42142937 0.41945818\n",
      "  0.41491842 0.41196084 0.40976048 0.40857354]\n",
      " [1.         0.5570033  0.5196859  0.4648858  0.46198994 0.44480523\n",
      "  0.4401177  0.43372825 0.4314283  0.4273808 ]\n",
      " [1.         0.521953   0.47057778 0.44119346 0.4381817  0.43022355\n",
      "  0.42291975 0.42260984 0.42183673 0.419215  ]\n",
      " [0.99999976 0.5307981  0.50673515 0.49549836 0.47322854 0.46735194\n",
      "  0.46197814 0.4441327  0.44299316 0.44154936]\n",
      " [1.         0.6529528  0.52930284 0.52685237 0.50188696 0.49158356\n",
      "  0.48155507 0.4702543  0.46897858 0.46824574]\n",
      " [1.         0.50953496 0.47928196 0.46199363 0.45223796 0.44858813\n",
      "  0.4428588  0.43613154 0.43533218 0.43359637]\n",
      " [0.99999976 0.5211427  0.49922833 0.49786347 0.4741562  0.46979028\n",
      "  0.4636337  0.4555797  0.44936016 0.44441307]\n",
      " [1.         0.5570033  0.54681844 0.49976733 0.48344773 0.4661773\n",
      "  0.46153635 0.449273   0.4460442  0.43861955]\n",
      " [0.99999976 0.5320695  0.52930284 0.5261108  0.5105853  0.50855225\n",
      "  0.4913523  0.47699627 0.47198725 0.45872176]\n",
      " [0.9999999  0.5724062  0.5307981  0.5118264  0.51034826 0.50339174\n",
      "  0.501045   0.48344773 0.47671738 0.47265863]\n",
      " [1.         0.47963396 0.45571497 0.45457628 0.44137657 0.42476687\n",
      "  0.42435697 0.423254   0.4225601  0.4207391 ]\n",
      " [1.         0.5625773  0.46703717 0.4590307  0.45494702 0.45097852\n",
      "  0.44306234 0.44249347 0.44187468 0.44058087]\n",
      " [0.9999999  0.54071164 0.4698076  0.46285087 0.4576718  0.45313233\n",
      "  0.45237496 0.44174495 0.4405913  0.4391201 ]\n",
      " [1.         0.58574885 0.5495299  0.5240287  0.5204377  0.5198173\n",
      "  0.50188696 0.49732462 0.48571888 0.4770815 ]\n",
      " [1.         0.46712545 0.45957178 0.45786965 0.45735508 0.4460542\n",
      "  0.44523752 0.4446891  0.44185832 0.4387027 ]\n",
      " [0.99999976 0.5170458  0.49687293 0.450945   0.44698486 0.44441307\n",
      "  0.4437186  0.43911436 0.4315553  0.4274068 ]\n",
      " [0.99999976 0.5724062  0.52165425 0.5147221  0.51157135 0.5035349\n",
      "  0.47322854 0.4648858  0.46192425 0.4591599 ]\n",
      " [1.         0.47426414 0.46481818 0.46109292 0.4606309  0.46000195\n",
      "  0.45661238 0.4531017  0.4516382  0.4405808 ]\n",
      " [0.99999976 0.4908251  0.46153635 0.4575494  0.45275173 0.45271423\n",
      "  0.4505676  0.44154936 0.4396499  0.4381817 ]\n",
      " [1.         0.45841923 0.45457628 0.4444694  0.44078293 0.4378327\n",
      "  0.42711762 0.4264719  0.42601988 0.42573735]\n",
      " [1.         0.5218735  0.52165425 0.50339174 0.47471613 0.46393347\n",
      "  0.46288696 0.4470281  0.4441327  0.44224498]\n",
      " [1.         0.5269098  0.52451956 0.4895827  0.48855808 0.4483141\n",
      "  0.4467967  0.44578537 0.44446355 0.44119346]\n",
      " [1.         0.5658286  0.5577943  0.54552174 0.5295911  0.52953595\n",
      "  0.5240287  0.5232887  0.51868665 0.51499736]\n",
      " [1.         0.43706217 0.4275818  0.42749143 0.42655993 0.423254\n",
      "  0.41479158 0.40802586 0.4048002  0.404128  ]\n",
      " [0.9999995  0.52765954 0.501291   0.4895827  0.44960168 0.4376025\n",
      "  0.43667156 0.4336407  0.42893136 0.42308852]\n",
      " [0.9999994  0.5625773  0.4900339  0.47071376 0.46307197 0.45733503\n",
      "  0.45075122 0.45054242 0.44549543 0.44192758]\n",
      " [1.         0.47069713 0.46307197 0.45012483 0.4495113  0.4286053\n",
      "  0.42685446 0.42660332 0.4248908  0.421567  ]\n",
      " [1.         0.5261108  0.4768151  0.4715878  0.46868378 0.46199363\n",
      "  0.4569664  0.4520586  0.4401177  0.4396685 ]\n",
      " [1.         0.55838406 0.50815773 0.49617562 0.4908251  0.4741562\n",
      "  0.4527767  0.44968835 0.44889435 0.44026765]\n",
      " [1.         0.44931605 0.4460442  0.42965454 0.42658213 0.420873\n",
      "  0.4183746  0.4166052  0.41594157 0.41382656]\n",
      " [0.9999999  0.50673515 0.44661582 0.4285631  0.4262237  0.42533526\n",
      "  0.42253935 0.4212427  0.4202017  0.41871953]\n",
      " [0.99999964 0.4089004  0.40408632 0.3928147  0.38973585 0.38736007\n",
      "  0.3839586  0.38391453 0.383273   0.38238814]\n",
      " [1.         0.50652975 0.46868378 0.46393347 0.45840254 0.45061433\n",
      "  0.44942167 0.44875526 0.44299316 0.43888012]\n",
      " [1.         0.501291   0.45957178 0.458844   0.45748243 0.4483141\n",
      "  0.4457816  0.44249347 0.4420798  0.43197528]\n",
      " [0.99999976 0.6553483  0.5658286  0.5315302  0.5276895  0.52651113\n",
      "  0.52513665 0.501045   0.4999978  0.4797794 ]\n",
      " [0.99999964 0.52500117 0.49976733 0.47265863 0.4470281  0.44480523\n",
      "  0.44231203 0.42658213 0.40727878 0.40505967]\n",
      " [1.         0.47512338 0.46203938 0.4584902  0.45671937 0.4405383\n",
      "  0.44006774 0.43957862 0.43911436 0.43775597]\n",
      " [1.         0.5198173  0.5158836  0.49478212 0.48916617 0.48855808\n",
      "  0.48355246 0.46897858 0.46714503 0.46625257]\n",
      " [0.99999917 0.50377375 0.500976   0.46579275 0.46267027 0.46203938\n",
      "  0.4511192  0.450945   0.44341734 0.4405913 ]\n",
      " [0.99999976 0.4776685  0.4667654  0.4661773  0.45939937 0.4495113\n",
      "  0.431595   0.41988984 0.41825306 0.41434678]\n",
      " [0.99999976 0.49478212 0.47525698 0.47513035 0.47343028 0.47042137\n",
      "  0.46629384 0.46052957 0.45494702 0.45075122]\n",
      " [1.         0.54071164 0.53412133 0.50703686 0.50377375 0.49687293\n",
      "  0.48618463 0.47032627 0.4637457  0.4527005 ]\n",
      " [0.99999976 0.500976   0.48618463 0.48422334 0.46301308 0.45604908\n",
      "  0.45237496 0.44806013 0.4449926  0.43957862]\n",
      " [1.         0.5043197  0.47471613 0.4577844  0.45468357 0.45187372\n",
      "  0.44231203 0.44160435 0.43857843 0.43512413]\n",
      " [1.         0.6553483  0.52924216 0.5218684  0.51868665 0.51532567\n",
      "  0.51034826 0.4950772  0.48571888 0.47709182]\n",
      " [0.9999995  0.54681844 0.5196859  0.4626162  0.46197814 0.44996285\n",
      "  0.44432023 0.4415783  0.44058087 0.43851328]\n",
      " [1.         0.51530945 0.45861462 0.45489413 0.44582295 0.43314224\n",
      "  0.42754668 0.42711762 0.4256065  0.42375314]\n",
      " [0.99999964 0.60603386 0.53358525 0.5008072  0.49922833 0.49617562\n",
      "  0.4842072  0.4800893  0.47198725 0.4703276 ]\n",
      " [0.9999999  0.4267483  0.42653468 0.4256674  0.42083275 0.41971195\n",
      "  0.4168048  0.41594157 0.4138351  0.4100574 ]\n",
      " [0.99999964 0.51560885 0.4768151  0.46735194 0.45061433 0.44295096\n",
      "  0.43843758 0.4285839  0.42857447 0.42839462]\n",
      " [1.         0.57823974 0.5274744  0.5232887  0.4999978  0.48679924\n",
      "  0.47207144 0.4687383  0.46570295 0.46000195]\n",
      " [0.99999964 0.4267483  0.42384756 0.409219   0.40819505 0.4064795\n",
      "  0.40482414 0.40386403 0.40209997 0.4019694 ]\n",
      " [1.         0.54562914 0.52765954 0.5269098  0.47513035 0.45435125\n",
      "  0.4457816  0.4439036  0.44248927 0.4377297 ]\n",
      " [1.         0.54582864 0.52065456 0.51492995 0.47825453 0.4494413\n",
      "  0.4416651  0.44137657 0.42510852 0.41568217]\n",
      " [1.         0.5977655  0.48922935 0.46712545 0.46682245 0.45939937\n",
      "  0.45747554 0.45571497 0.45096016 0.4463642 ]\n",
      " [0.99999976 0.52500117 0.4331564  0.43307558 0.42106423 0.40350813\n",
      "  0.40039238 0.40028757 0.39616725 0.3945751 ]\n",
      " [0.99999976 0.45869488 0.443944   0.43458608 0.42930382 0.42510852\n",
      "  0.42414886 0.42138907 0.41940314 0.41899204]\n",
      " [1.         0.6441328  0.48279202 0.47642422 0.46262455 0.46052957\n",
      "  0.45736593 0.45671937 0.44582295 0.4446891 ]\n",
      " [1.         0.5977655  0.4776685  0.4722282  0.4555744  0.4500409\n",
      "  0.4450149  0.44468465 0.4444694  0.44185832]\n",
      " [0.99999976 0.5577943  0.5083099  0.4901989  0.4674619  0.45939544\n",
      "  0.45432428 0.4521593  0.44767454 0.44708717]\n",
      " [1.         0.51560885 0.45869488 0.4541582  0.44942167 0.44257826\n",
      "  0.44089907 0.4338121  0.4321929  0.4308437 ]\n",
      " [1.         0.53412133 0.5170458  0.4800893  0.47699627 0.4742038\n",
      "  0.47071376 0.46629384 0.4645673  0.4636337 ]\n",
      " [0.9999999  0.52953595 0.52916855 0.5276895  0.5147221  0.5118264\n",
      "  0.49912742 0.4950772  0.4913523  0.4901989 ]\n",
      " [1.         0.5240897  0.5204377  0.5158836  0.49865648 0.48679924\n",
      "  0.48155507 0.4782974  0.47442567 0.4739656 ]\n",
      " [1.         0.4974467  0.47874284 0.47780707 0.4531674  0.4416651\n",
      "  0.4244136  0.42246872 0.41672125 0.41487828]\n",
      " [1.         0.4396499  0.43657914 0.43461943 0.42548677 0.424853\n",
      "  0.4241508  0.42260984 0.42238995 0.422185  ]\n",
      " [0.99999976 0.5320695  0.5008072  0.4962931  0.47928196 0.4715878\n",
      "  0.47149897 0.47101197 0.46979028 0.464107  ]\n",
      " [0.99999976 0.4722282  0.46682245 0.4667654  0.44841164 0.4416522\n",
      "  0.4410732  0.4386861  0.43725327 0.43433434]\n",
      " [1.         0.49593148 0.47959894 0.4687383  0.46636328 0.46390742\n",
      "  0.46222147 0.4582871  0.4555797  0.4531017 ]\n",
      " [0.99999976 0.4626162  0.4449926  0.44174495 0.4381843  0.4353415\n",
      "  0.43324292 0.4326079  0.4227102  0.4217889 ]\n",
      " [1.         0.47407824 0.45815867 0.45489413 0.4396685  0.4387265\n",
      "  0.43182063 0.43153816 0.43082643 0.41828176]\n",
      " [1.         0.54562914 0.52451956 0.521953   0.50519943 0.46262455\n",
      "  0.45861462 0.45841923 0.45748243 0.45735508]\n",
      " [0.99999976 0.52916855 0.5269311  0.5105853  0.50953496 0.5026481\n",
      "  0.49732462 0.4962931  0.49158356 0.4900339 ]\n",
      " [1.         0.5218735  0.51157135 0.50652975 0.48818013 0.47709182\n",
      "  0.47331876 0.46872142 0.4541582  0.45194504]\n",
      " [1.         0.45012483 0.44204792 0.4386881  0.431014   0.424853\n",
      "  0.42220578 0.4147137  0.41385832 0.41319364]\n",
      " [1.         0.5035349  0.4494413  0.4466693  0.43591365 0.42881244\n",
      "  0.41793528 0.41740257 0.41571388 0.41553238]\n",
      " [1.         0.58574885 0.5424829  0.52651113 0.5218684  0.51499736\n",
      "  0.49912742 0.49865648 0.47426414 0.47331876]\n",
      " [1.         0.45661777 0.43372354 0.43251094 0.43206903 0.42749143\n",
      "  0.4257407  0.4244136  0.42309904 0.4218928 ]\n",
      " [1.         0.58750373 0.58622867 0.56353515 0.47825453 0.45558196\n",
      "  0.4531674  0.43372354 0.42803097 0.42704976]\n",
      " [1.         0.54552174 0.52764255 0.5083099  0.5014589  0.4864815\n",
      "  0.47098148 0.4702543  0.4695431  0.45840278]\n",
      " [1.         0.6208895  0.5315302  0.5295911  0.5274744  0.51532567\n",
      "  0.49593148 0.4864815  0.4854552  0.4782974 ]\n",
      " [0.9999999  0.47963396 0.47352046 0.46409804 0.46225205 0.45747554\n",
      "  0.45736593 0.45558196 0.45414054 0.44523752]\n",
      " [0.99999976 0.55441284 0.52685237 0.5014589  0.4739717  0.46144024\n",
      "  0.45245138 0.4504395  0.44493222 0.44470584]\n",
      " [0.9999999  0.47069713 0.45194504 0.45187372 0.44858813 0.44187468\n",
      "  0.44054136 0.43827838 0.43538067 0.43431547]\n",
      " [1.         0.4637457  0.45897922 0.4576718  0.44805306 0.44698486\n",
      "  0.44341734 0.4417726  0.43982545 0.43614882]\n",
      " [0.99999976 0.51530945 0.50519943 0.48922935 0.47642422 0.47073647\n",
      "  0.47042137 0.46409804 0.458844   0.45815867]\n",
      " [1.         0.6529528  0.55441284 0.5495299  0.5424829  0.52764255\n",
      "  0.5269311  0.5240897  0.514524   0.50855225]\n",
      " [0.99999964 0.6441328  0.44369742 0.4381268  0.43709093 0.43688536\n",
      "  0.43562376 0.43499422 0.43426    0.4330038 ]\n",
      " [1.         0.6581356  0.65242666 0.58622867 0.51492995 0.47874284\n",
      "  0.45661777 0.4466693  0.43822923 0.42984518]\n",
      " [0.9999999  0.5026481  0.48279202 0.47407824 0.47073647 0.46753058\n",
      "  0.46703717 0.46225205 0.44728136 0.44549543]]\n",
      "CPU times: user 57.4 ms, sys: 11.4 ms, total: 68.8 ms\n",
      "Wall time: 56.7 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "fractal_dimensions = calculate_fractal_value(normalized_embeddings,5,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fractal Dimension: [2.321928094887362, 2.321928094887362, 2.321928094887362, 0.0, 0.0, 2.321928094887362, 1.5849625007211563, 1.0, 0.0, 1.5849625007211563, 1.0, 1.5849625007211563, 2.321928094887362, 1.0, 1.0, 1.5849625007211563, 2.584962500721156, 2.807354922057604, 0.0, 1.0, 1.0, 2.807354922057604, 0.0, 1.0, 2.584962500721156, 0.0, 0.0, 0.0, 2.0, 1.5849625007211563, 3.3219280948873626, 0.0, 1.5849625007211563, 1.0, 0.0, 1.0, 1.5849625007211563, 0.0, 1.0, 0.0, 1.0, 1.0, 3.0, 1.0, 0.0, 1.5849625007211563, 1.5849625007211563, 0.0, 0.0, 2.321928094887362, 1.0, 1.0, 2.807354922057604, 1.5849625007211563, 1.0, 2.0, 0.0, 1.0, 2.0, 0.0, 2.0, 2.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.5849625007211563, 1.0, 1.5849625007211563, 2.584962500721156, 2.0, 0.0, 0.0, 1.5849625007211563, 0.0, 0.0, 0.0, 0.0, 2.321928094887362, 2.584962500721156, 2.0, 0.0, 1.0, 2.584962500721156, 0.0, 2.0, 2.321928094887362, 2.584962500721156, 0.0, 2.0, 0.0, 0.0, 1.5849625007211563, 3.3219280948873626, 1.0, 2.321928094887362, 1.0]\n"
     ]
    }
   ],
   "source": [
    "print(\"Fractal Dimension:\", fractal_dimensions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Fractal_dimension_non_polysemous_words_100_5_10', 'w') as f:\n",
    "    for dimension in fractal_dimensions:\n",
    "        f.write(str(dimension) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98\n"
     ]
    }
   ],
   "source": [
    "print(len(open('Fractal_dimension_non_polysemous_words_100_5_10', 'r').readlines()))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
