{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "X28zqoct9wvx"
   },
   "outputs": [],
   "source": [
    "import gzip\n",
    "import gensim \n",
    "import logging\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v6cM9qG99wv-",
    "outputId": "3b235704-4a97-4ebd-836a-d276ed6193db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving notices: ...working... done\n",
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 23.3.1\n",
      "  latest version: 23.5.0\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "Or to minimize the number of packages updated during conda update use\n",
      "\n",
      "     conda install conda=23.5.0\n",
      "\n",
      "\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#use (!pip install fasttext) with collab\n",
    "conda install -c conda-forge fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y1itQb_kHZKq",
    "outputId": "f1b5c54f-3680-4e33-c373-3f9ad5902e5c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gdown in /Users/akallaku/anaconda3/lib/python3.10/site-packages (4.7.1)\n",
      "Requirement already satisfied: tqdm in /Users/akallaku/anaconda3/lib/python3.10/site-packages (from gdown) (4.64.1)\n",
      "Requirement already satisfied: six in /Users/akallaku/anaconda3/lib/python3.10/site-packages (from gdown) (1.16.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /Users/akallaku/anaconda3/lib/python3.10/site-packages (from gdown) (4.11.1)\n",
      "Requirement already satisfied: requests[socks] in /Users/akallaku/anaconda3/lib/python3.10/site-packages (from gdown) (2.28.1)\n",
      "Requirement already satisfied: filelock in /Users/akallaku/anaconda3/lib/python3.10/site-packages (from gdown) (3.9.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/akallaku/anaconda3/lib/python3.10/site-packages (from beautifulsoup4->gdown) (2.3.2.post1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/akallaku/anaconda3/lib/python3.10/site-packages (from requests[socks]->gdown) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/akallaku/anaconda3/lib/python3.10/site-packages (from requests[socks]->gdown) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/akallaku/anaconda3/lib/python3.10/site-packages (from requests[socks]->gdown) (2023.5.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/akallaku/anaconda3/lib/python3.10/site-packages (from requests[socks]->gdown) (1.26.14)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /Users/akallaku/anaconda3/lib/python3.10/site-packages (from requests[socks]->gdown) (1.7.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HRnK2mxcHZKr",
    "outputId": "10351240-7156-4cf2-ec41-533cbe1f16b5"
   },
   "outputs": [],
   "source": [
    "# Download the FastText model file if it doesn't exist\n",
    "import os\n",
    "import gdown\n",
    "if not os.path.exists('cc.en.300.bin'):\n",
    "        url = 'https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.en.300.bin.gz'\n",
    "        output = 'cc.en.300.bin.gz'\n",
    "        gdown.download(url, output, quiet=False)\n",
    "\n",
    "        with gzip.open(output, 'rb') as f_in:\n",
    "            with open('cc.en.300.bin', 'wb') as f_out:\n",
    "                f_out.write(f_in.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gmT4xRWDHZKs",
    "outputId": "b2a76d9d-660e-4251-c12c-b1b61b7310e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "import fasttext.util\n",
    "\n",
    "model_path = 'cc.en.300.bin'\n",
    "\n",
    "model = fasttext.load_model(model_path)\n",
    "\n",
    "# Get the word embeddings\n",
    "embeddings = model.get_input_matrix()\n",
    "\n",
    "# Create a dictionary to store the word embeddings\n",
    "documents = []\n",
    "word_embeddings = {}\n",
    "\n",
    "# Populate the dictionary with word embeddings\n",
    "for word, vector in zip(model.get_words(), embeddings):\n",
    "    word_embeddings[word] = vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CNOsq_5rHZKu",
    "outputId": "a8e70e43-dee5-40c2-bf93-54ac86f20487"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000000\n"
     ]
    }
   ],
   "source": [
    "print(len(word_embeddings.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "-SVZevuYHZKw"
   },
   "outputs": [],
   "source": [
    "def pick_word_embeddings(non_polysemous):\n",
    "    non_polysemous_embeddings = {}\n",
    "    for word in non_polysemous:\n",
    "        if(word in word_embeddings):\n",
    "            non_polysemous_embeddings[word] = word_embeddings[word]\n",
    "    \n",
    "    return non_polysemous_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_polysemous = [\n",
    "    \"banana\", \"guitar\", \"elephant\", \"chair\", \"diamond\", \"piano\", \"lemon\", \"mountain\", \"book\", \"sun\",\n",
    "    \"umbrella\", \"river\", \"butterfly\", \"tree\", \"carrot\", \"moon\", \"flower\", \"ocean\", \"computer\", \"lamp\",\n",
    "    \"coffee\", \"bird\", \"bicycle\", \"cookie\", \"beach\", \"dog\", \"rainbow\", \"camera\", \"island\", \"hat\",\n",
    "    \"turtle\", \"clock\", \"socks\", \"candle\", \"fire\", \"garden\", \"orange\", \"star\", \"bridge\", \"key\",\n",
    "    \"castle\", \"shoe\", \"dolphin\", \"planet\", \"spoon\", \"feather\", \"butter\", \"rocket\", \"pillow\", \"chocolate\",\n",
    "    \"honey\", \"volcano\", \"whale\", \"moonlight\", \"wallet\", \"pineapple\", \"flag\", \"fountain\", \"tiger\", \"map\",\n",
    "    \"sweater\", \"music\", \"airplane\", \"globe\", \"painting\", \"toothbrush\", \"helicopter\", \"snail\", \"statue\", \"cupcake\",\n",
    "    \"seashell\", \"peacock\", \"drum\", \"cloud\", \"cactus\", \"feather\", \"balloon\", \"kangaroo\", \"moonshine\", \"mailbox\",\n",
    "    \"raincoat\", \"pinecone\", \"lighthouse\", \"tornado\", \"volleyball\", \"seagull\", \"whistle\", \"accordion\", \"tadpole\", \"giraffe\",\n",
    "    \"typewriter\", \"caterpillar\", \"chimney\", \"waffle\", \"suitcase\", \"butterfly\", \"dragonfly\", \"toothpaste\", \"saxophone\", \"doorknob\"\n",
    "]\n",
    "\n",
    "non_polysemous_embeddings = pick_word_embeddings(non_polysemous)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rJs8ecLWNzgW",
    "outputId": "4cfa8221-e0e4-4d46-915c-d28080f168f6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(non_polysemous_embeddings.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "flXXA-L9GSGX"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "def normalize_word_embeddings(word_embeddings):\n",
    "    # Extract the word vectors and store them in a numpy array\n",
    "    embeddings = np.array(list(word_embeddings.values()))\n",
    "\n",
    "    # Normalize the word embeddings\n",
    "    normalized_embeddings = normalize(embeddings)\n",
    "\n",
    "    # Update the normalized embeddings back in the dictionary\n",
    "    for i, word in enumerate(word_embeddings.keys()):\n",
    "        word_embeddings[word] = normalized_embeddings[i]\n",
    "\n",
    "    return word_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "O8BHr5yyNzgY"
   },
   "outputs": [],
   "source": [
    "# Call the function to get normalized word embeddings\n",
    "normalized_embeddings = normalize_word_embeddings(non_polysemous_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QeitKg2FjfUB",
    "outputId": "d646be92-67ab-4703-b00e-3ecba583f459"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 23.3.1\n",
      "  latest version: 23.5.0\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "Or to minimize the number of packages updated during conda update use\n",
      "\n",
      "     conda install conda=23.5.0\n",
      "\n",
      "\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda install -c conda-forge faiss\n",
    "#use (!pip install faiss-gpu) with collab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def embedding_cosine_similarity(embedding1,embedding2):\n",
    "    embedding1 = embedding1.reshape(1, -1)\n",
    "    embedding2 = embedding2.reshape(1, -1)\n",
    "    return cosine_similarity(embedding1,embedding2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "G3qfNg9ONzga"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import faiss\n",
    "\n",
    "'''\n",
    "num_clusters = 256  \n",
    "quantizer = faiss.IndexFlatL2(embedding_vectors.shape[1])\n",
    "index = faiss.IndexIVFFlat(quantizer, embedding_vectors.shape[1], num_clusters)\n",
    "index.train(embedding_vectors)\n",
    "index.add(embedding_vectors)\n",
    "_, similar_indices = index.search(embedding_vectors, num_similar)\n",
    "\n",
    "'''\n",
    "\n",
    "def calculate_fractal_value(embeddings, box_size, k):\n",
    "    \n",
    "    embedding_vectors = np.array(list(embeddings.values()))\n",
    "    \n",
    "    # Initialize Faiss index\n",
    "    embedding_dim = embedding_vectors.shape[1]\n",
    "    index = faiss.IndexFlatL2(embedding_dim)\n",
    "\n",
    "    # Add embeddings to the Faiss index\n",
    "    index.add(embedding_vectors)\n",
    "\n",
    "    # Search for the nearest neighbors of all vectors\n",
    "    neighbor_distances , neighbor_indices = index.search(embedding_vectors, k)\n",
    "    \n",
    "    print(neighbor_indices)\n",
    "    \n",
    "    # Calculating cosine similarity values using the neighbor_distances and updating it.\n",
    "    for i in range(neighbor_distances.shape[0]):\n",
    "        for j in range(neighbor_distances.shape[1]):\n",
    "            neighbor_distances[i][j] = embedding_cosine_similarity(embedding_vectors[i],embedding_vectors[neighbor_indices[i][j]])\n",
    "    \n",
    "    print(neighbor_distances)\n",
    "\n",
    "    #Resultant fractal dimension array\n",
    "    fractal_dimensions = []\n",
    "\n",
    "    for i in range(embedding_vectors.shape[0]):\n",
    "        num_boxes = 0\n",
    "        num_filled_boxes = 0\n",
    "\n",
    "        # Iterate over the similarity scores of each vector in chunks of box_size\n",
    "        for j in range(0,neighbor_distances.shape[1],box_size):\n",
    "            box_scores = neighbor_distances[i,j:j+box_size]\n",
    "            \n",
    "            for score in box_scores:\n",
    "                if(score>0.5):\n",
    "                    num_filled_boxes += 1\n",
    "\n",
    "            num_boxes+=1\n",
    "\n",
    "        fractal_dimension = np.log(num_filled_boxes) / np.log(num_boxes)\n",
    "        fractal_dimensions.append(fractal_dimension)\n",
    "\n",
    "    return fractal_dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "Y03oXI0RNzga"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0 55 14 36 49  6 20 46 69 50]\n",
      " [ 1  5 96 86 61 72 89 83 22 38]\n",
      " [ 2 88 58 52 42 30 76 70 71 25]\n",
      " [ 3 48 10 19 97 93 89 60 22 18]\n",
      " [ 4 37 70 16 55 45 15 41 69 94]\n",
      " [ 5 96  1 86 61 72 89 64 83 70]\n",
      " [ 6 36 55  0 14 50 46 74 49 69]\n",
      " [ 7 51 11 17 28 22 66 24 40 74]\n",
      " [ 8 62 89 59 48 93  3 60 64 20]\n",
      " [ 9 15 53 24 17 43 35 26 19 74]\n",
      " [10 79  3 29 26 93  9 73 48 19]\n",
      " [11 17 38  7 24 57 53 28 40 26]\n",
      " [12 94 16 90 21 80 71 87 45 30]\n",
      " [13 80 74 35 16 91  7 33 21 88]\n",
      " [14  0 55  6 36 74 69 76 49 23]\n",
      " [15  9 53 43 17 47 26 84 37 94]\n",
      " [16 74 12 35 80 94 70 69 55 71]\n",
      " [17 24 11 70 52 28 42 15  7 43]\n",
      " [18 89 62 27 61  3 97 31 20  5]\n",
      " [19 33 97  3 48 81 80 41 91 53]\n",
      " [20 49  0 69 92 55 50 77 46 33]\n",
      " [21 84 94 30 71 45 12 80 52 42]\n",
      " [22 62 41  7 79 93 89 65 66 35]\n",
      " [23 69 49 46 92 14 80 44  0 20]\n",
      " [24 17 28 70 81 83 11  9 84 42]\n",
      " [25 84 30 21  2 58 42 76 88 52]\n",
      " [26 36 15 71 94 12 16 11 73 10]\n",
      " [27 79 18 66 62 93 54 24 84 53]\n",
      " [28 81 24 17 51 40  7 43 11 55]\n",
      " [29 60 79 32 45 41 69 93 80 10]\n",
      " [30 42 67 87 88 70 21 58 52 84]\n",
      " [31 97 15 85 19 18 89 33 81 30]\n",
      " [32 60 41 29 79 93 65 48 95 97]\n",
      " [33 19 80 69 34 70 48 16 97 49]\n",
      " [34 91 33 82 47 66 51  9 19 53]\n",
      " [35 16 57 74 40 13 24 12  9 78]\n",
      " [36  6  0 55 26 14 71 49 74 16]\n",
      " [37  4 15 80 43 88  9 45 56 83]\n",
      " [38 11 81 40 68 57 17 53  1 91]\n",
      " [39 97 54 59  4  5 70 29 37 93]\n",
      " [40 81 35 28 24 57 68  7 11 66]\n",
      " [41 32 22 93 79 29 60 19 65 48]\n",
      " [42 52 30 88 70 84  2 17 58 94]\n",
      " [43 63 15 17 28  9 51 37  7 18]\n",
      " [44 80 46 69 65 97 14 50 23 49]\n",
      " [45 21 71 48 80 29 94 12 70 84]\n",
      " [46 49 50  0  6 44 55 23 92 20]\n",
      " [47 66 75 15 62 34 84 14 76 94]\n",
      " [48 45  3 60 70 93 69 65 19 33]\n",
      " [49 20 69  0 46 23 50 55 92  6]\n",
      " [50 46 49  6  0 55 20 16 77 44]\n",
      " [51  7 28 17 74 91 43 55 66 81]\n",
      " [52 42  2 84 30 88 17 70 21 81]\n",
      " [53 15  9 77 11 81 17 33 19 24]\n",
      " [54 93 79 78 65 48 29 27 97 41]\n",
      " [55  0  6 74 14 36 70 69 16 80]\n",
      " [56 59 68 26 84 13 29 37 71 33]\n",
      " [57 68 35 11 40 16 19 74 42 49]\n",
      " [58  2 88 30 42 71 94 76 52 25]\n",
      " [59 56  8 28 81 11 40 93 13 27]\n",
      " [60 79 32 29 48 93 41 80 69 70]\n",
      " [61  5  1 96 86 83 72 18 64 77]\n",
      " [62 66 93 22 75 47 89 18 84 21]\n",
      " [63 43 17 28 15 80 31 51  9 19]\n",
      " [64 68  5 35 16 61 80 40 70  1]\n",
      " [65 95 97 93 79 48 89 44 54 22]\n",
      " [66 62 47 75 84  7 94 21 27 22]\n",
      " [67 30 87 70 94 80 42 58 88 74]\n",
      " [68 57 64 81 40 70  2 84 80 35]\n",
      " [69 49 23 55 16 80 33 48  0 14]\n",
      " [70 30 80 42 24 17 84 52 16 67]\n",
      " [71 94 21 45 84 58 12 88 30  2]\n",
      " [72  1 96  5 86 61 85 89 70  2]\n",
      " [73 26  7 15 17 82 53 10 51 79]\n",
      " [74 16 55 80 13 35 30 94 14 70]\n",
      " [75 66 62 47 69 88 16  2 22 42]\n",
      " [76 88  2 58 42 52 30 21 14 25]\n",
      " [77 53 50 20 15  6 74 55 87  9]\n",
      " [78 97 93 54 35 89 67 80 13 18]\n",
      " [79 60 29 10 93 65 54 27 41 22]\n",
      " [80 70 94 16 13 97 21 74 12 33]\n",
      " [81 28 24 40 70 52 84 17 68 91]\n",
      " [82 34 62 66 51 73 94 91 13 97]\n",
      " [83 24 61 96  1  5 22 35 32 41]\n",
      " [84 21 94 42 52 30 70 71 25 81]\n",
      " [85 96 86 29 45 31 84 72 91 25]\n",
      " [86  5 96  1 61 89 72 85 70 79]\n",
      " [87 30 94 67 90 88 42 12 52 84]\n",
      " [88  2 42 30 58 52 76 87 94 71]\n",
      " [89 18  5 93 97 62 65 86  1 22]\n",
      " [90 94 12 87 88 30 58 80 16 74]\n",
      " [91 34 81 51 13 19 80 40  7 97]\n",
      " [92 49 69 20 55 23 46 48  0 44]\n",
      " [93 54 79 62 65 97 48 89 41 78]\n",
      " [94 12 90 21 84 87 80 71 30 16]\n",
      " [95 65 49 93 50  0  6 69 44 70]\n",
      " [96  5  1 86 61 72 85 83 89 79]\n",
      " [97 80 65 78 93 70 19 89  3 33]]\n",
      "[[1.0000001  0.67496365 0.54056996 0.51605356 0.51387846 0.49965507\n",
      "  0.4357346  0.42656147 0.4237298  0.42011702]\n",
      " [1.         0.7402736  0.7336303  0.6127438  0.5396703  0.49486718\n",
      "  0.39901924 0.3529838  0.31773177 0.31009513]\n",
      " [1.         0.69470364 0.6353066  0.55525273 0.5478668  0.4979606\n",
      "  0.45746213 0.44941863 0.44507095 0.41453215]\n",
      " [1.0000001  0.44793788 0.43747646 0.4107483  0.38213557 0.35709426\n",
      "  0.33601993 0.33492485 0.3265855  0.32288384]\n",
      " [1.         0.3871976  0.376085   0.35355955 0.34242627 0.3410135\n",
      "  0.3253444  0.32223594 0.3068231  0.30561268]\n",
      " [1.         0.7402782  0.7402736  0.64894146 0.5839615  0.45355242\n",
      "  0.44407934 0.37373194 0.333989   0.3317196 ]\n",
      " [1.0000001  0.60455894 0.56294274 0.49965507 0.49570858 0.46741864\n",
      "  0.419317   0.40820727 0.3955171  0.38285795]\n",
      " [1.         0.5085653  0.49091494 0.4511606  0.41982278 0.40798625\n",
      "  0.38898984 0.38650322 0.38580683 0.38101384]\n",
      " [1.         0.35069293 0.32149518 0.32033065 0.3135616  0.307986\n",
      "  0.2949439  0.28629237 0.2797749  0.2762301 ]\n",
      " [1.0000001  0.6023394  0.5378805  0.42446706 0.4177253  0.37591252\n",
      "  0.36394015 0.34720445 0.34105882 0.33008322]\n",
      " [1.0000001  0.5420593  0.43747646 0.36671022 0.35892084 0.3378135\n",
      "  0.31774256 0.31687552 0.3147073  0.30729446]\n",
      " [1.0000001  0.5580224  0.51329136 0.49091494 0.44342822 0.43014246\n",
      "  0.41769776 0.37421027 0.37131435 0.36762384]\n",
      " [1.         0.7342477  0.5553613  0.55096763 0.5037595  0.48287892\n",
      "  0.461697   0.4367454  0.4338532  0.4321846 ]\n",
      " [1.0000002  0.51871306 0.4567728  0.41773412 0.3943874  0.38539195\n",
      "  0.37097192 0.35355693 0.35145175 0.34685385]\n",
      " [1.         0.54056996 0.49845427 0.49570858 0.44549522 0.43569523\n",
      "  0.4215625  0.40249717 0.3873068  0.37492058]\n",
      " [1.0000001  0.6023394  0.5856198  0.4995345  0.46576214 0.42744684\n",
      "  0.41666183 0.3870908  0.3790349  0.36005998]\n",
      " [0.99999994 0.5602732  0.5553613  0.5496298  0.5207318  0.5168169\n",
      "  0.4824001  0.4517738  0.44064933 0.4100145 ]\n",
      " [1.0000001  0.62649447 0.5580224  0.5231063  0.5202769  0.5067378\n",
      "  0.5020857  0.46576214 0.4511606  0.4421542 ]\n",
      " [1.         0.4575383  0.40282303 0.40007457 0.3671804  0.32288384\n",
      "  0.32174674 0.31867623 0.31673628 0.31161496]\n",
      " [1.         0.61123323 0.4294215  0.4107483  0.40097094 0.39129972\n",
      "  0.3714907  0.37003976 0.36845744 0.3651346 ]\n",
      " [1.         0.5752928  0.4357346  0.4197384  0.40751404 0.39656967\n",
      "  0.39472222 0.3681253  0.36516166 0.36135948]\n",
      " [1.         0.6463918  0.5901313  0.5458539  0.5392702  0.5381234\n",
      "  0.5037595  0.49462038 0.4705978  0.45196104]\n",
      " [1.0000002  0.4296237  0.41203064 0.40798625 0.4067574  0.3790601\n",
      "  0.37700388 0.37561893 0.3684155  0.36027595]\n",
      " [1.0000001  0.53296775 0.4937065  0.39121747 0.38139382 0.37492058\n",
      "  0.37315986 0.36134443 0.3414     0.3301543 ]\n",
      " [1.0000001  0.62649447 0.54151094 0.52860194 0.5226192  0.50702024\n",
      "  0.44342822 0.42446706 0.41757143 0.411055  ]\n",
      " [1.         0.44573516 0.4243106  0.4156198  0.41453215 0.41304797\n",
      "  0.40497947 0.39649495 0.39291897 0.36513436]\n",
      " [1.0000001  0.48130724 0.41666183 0.40722182 0.39564213 0.39555055\n",
      "  0.3902886  0.36762384 0.3627315  0.35892084]\n",
      " [0.99999994 0.40929514 0.40007457 0.37506303 0.36565468 0.35801136\n",
      "  0.32936224 0.32758984 0.32634568 0.32556692]\n",
      " [1.0000001  0.54191345 0.54151094 0.5067378  0.44673893 0.42225933\n",
      "  0.41982278 0.3815021  0.37421027 0.36940488]\n",
      " [0.9999998  0.551071   0.54674673 0.478722   0.4765802  0.38471052\n",
      "  0.3809229  0.37838417 0.3750483  0.36671022]\n",
      " [1.0000002  0.6163404  0.60361236 0.58344626 0.5558753  0.5557771\n",
      "  0.5458539  0.5445047  0.536027   0.5291211 ]\n",
      " [1.0000001  0.35599807 0.33063307 0.3303859  0.32783175 0.31867623\n",
      "  0.2945753  0.27458745 0.2648228  0.2627682 ]\n",
      " [0.99999994 0.55241925 0.50257516 0.478722   0.38790455 0.35741067\n",
      "  0.3549746  0.34697172 0.33431238 0.31821424]\n",
      " [1.         0.61123323 0.4796624  0.43778345 0.42025423 0.40670958\n",
      "  0.39074078 0.3902266  0.377654   0.368593  ]\n",
      " [1.         0.43774587 0.42025423 0.389197   0.3876809  0.33342543\n",
      "  0.32864052 0.32795095 0.32322702 0.31394896]\n",
      " [0.99999994 0.5496298  0.45137534 0.43975207 0.43318254 0.41773412\n",
      "  0.40582773 0.3939486  0.36394015 0.36277956]\n",
      " [1.         0.60455894 0.51605356 0.4922923  0.48130724 0.44549522\n",
      "  0.39570284 0.38811877 0.3861521  0.3643272 ]\n",
      " [1.         0.3871976  0.3790349  0.33627447 0.3278928  0.31199303\n",
      "  0.30489874 0.29982293 0.297908   0.2917643 ]\n",
      " [0.99999994 0.51329136 0.38046953 0.33331063 0.326907   0.32445678\n",
      "  0.31667838 0.31303585 0.31009513 0.30588338]\n",
      " [1.0000001  0.27720842 0.26264066 0.2271353  0.21707979 0.2092112\n",
      "  0.19777624 0.19762678 0.19544697 0.19242817]\n",
      " [1.0000001  0.5128911  0.43318254 0.42225933 0.40925577 0.3904037\n",
      "  0.3874592  0.38580683 0.37131435 0.36073658]\n",
      " [1.0000002  0.50257516 0.41203064 0.41030505 0.40706173 0.38471052\n",
      "  0.37837437 0.37003976 0.36898246 0.34252638]\n",
      " [1.0000001  0.737047   0.6163404  0.55931973 0.55247325 0.5503524\n",
      "  0.5478668  0.5020857  0.49999568 0.45785442]\n",
      " [1.0000002  0.5476212  0.4995345  0.4421542  0.3815021  0.37591252\n",
      "  0.36957636 0.3278928  0.2723398  0.26561394]\n",
      " [1.         0.4476418  0.41784137 0.40946424 0.40523574 0.3650249\n",
      "  0.36381125 0.36254707 0.36134443 0.35781118]\n",
      " [1.0000001  0.5381234  0.53078914 0.48945418 0.47785255 0.4765802\n",
      "  0.4659861  0.4338532  0.42966855 0.42761973]\n",
      " [1.0000001  0.50749123 0.50194836 0.42656147 0.419317   0.41784137\n",
      "  0.39164573 0.39121747 0.37239423 0.36516166]\n",
      " [1.0000001  0.4532489  0.42879817 0.42744684 0.4116224  0.3876809\n",
      "  0.34150642 0.30921152 0.30455148 0.29328135]\n",
      " [1.         0.48945418 0.44793788 0.44765714 0.44387832 0.43712327\n",
      "  0.42771482 0.41429335 0.40097094 0.39074078]\n",
      " [1.0000001  0.5752928  0.5638832  0.51387846 0.50749123 0.4937065\n",
      "  0.47158408 0.43690848 0.42182285 0.3955171 ]\n",
      " [1.         0.50194836 0.47158408 0.46741864 0.42011702 0.40362674\n",
      "  0.39472222 0.38407832 0.37638593 0.36254707]\n",
      " [1.0000001  0.5085653  0.44673893 0.40778273 0.40033418 0.3934961\n",
      "  0.36957636 0.36776477 0.35995296 0.3509025 ]\n",
      " [1.0000001  0.737047   0.55525273 0.54190403 0.536027   0.52973974\n",
      "  0.5202769  0.4900565  0.4705978  0.45198363]\n",
      " [1.         0.5856198  0.5378805  0.41919076 0.41769776 0.38879716\n",
      "  0.3746855  0.36769816 0.3651346  0.35978386]\n",
      " [1.0000001  0.52970946 0.40976003 0.4008432  0.37847853 0.34564492\n",
      "  0.33053717 0.32936224 0.325206   0.32006773]\n",
      " [1.0000001  0.67496365 0.56294274 0.50161195 0.49845427 0.4922923\n",
      "  0.46738422 0.45852718 0.44064933 0.4369112 ]\n",
      " [1.         0.3283492  0.32776225 0.32537416 0.31187943 0.30870682\n",
      "  0.30039763 0.297908   0.29178914 0.28065857]\n",
      " [1.0000001  0.5302728  0.45137534 0.43014246 0.3904037  0.3712069\n",
      "  0.35958683 0.33336735 0.3333418  0.33285198]\n",
      " [1.         0.6353066  0.55208665 0.5445047  0.49999568 0.4728824\n",
      "  0.44083816 0.4333067  0.42635423 0.41304797]\n",
      " [1.         0.3283492  0.32033065 0.2781604  0.2750953  0.2699257\n",
      "  0.2648958  0.26195964 0.25652817 0.2561243 ]\n",
      " [1.         0.5836266  0.55241925 0.551071   0.44765714 0.39952987\n",
      "  0.37837437 0.37362933 0.37002912 0.3577426 ]\n",
      " [1.0000001  0.5839615  0.5396703  0.528994   0.4545316  0.3875077\n",
      "  0.36792052 0.3671804  0.3238298  0.297158  ]\n",
      " [0.99999994 0.6635515  0.4779844  0.4296237  0.42892897 0.4116224\n",
      "  0.40704536 0.40282303 0.39125448 0.3798384 ]\n",
      " [1.         0.5476212  0.3456826  0.34546712 0.31253275 0.26086766\n",
      "  0.25122502 0.2508979  0.23790678 0.23281407]\n",
      " [1.0000001  0.4099508  0.37373194 0.34948    0.33532375 0.3238298\n",
      "  0.3211685  0.31344816 0.30782956 0.30666003]\n",
      " [1.         0.7237625  0.46435747 0.45051512 0.41921002 0.41429335\n",
      "  0.40678346 0.40523574 0.37847853 0.37561893]\n",
      " [1.0000001  0.6635515  0.4532489  0.4411899  0.4024843  0.38898984\n",
      "  0.37644213 0.37560755 0.37506303 0.3684155 ]\n",
      " [1.0000001  0.60361236 0.5163482  0.48000604 0.4303942  0.41161317\n",
      "  0.39946482 0.39419505 0.3831173  0.38164997]\n",
      " [1.0000002  0.5302728  0.4099508  0.399062   0.3874592  0.37025625\n",
      "  0.3659535  0.34742725 0.34310913 0.3394864 ]\n",
      " [1.0000001  0.5638832  0.53296775 0.45852718 0.4517738  0.445601\n",
      "  0.43778345 0.42771482 0.4237298  0.4215625 ]\n",
      " [1.0000001  0.5557771  0.5551215  0.55247325 0.52860194 0.5231063\n",
      "  0.49825162 0.4900565  0.4824001  0.48000604]\n",
      " [0.9999999  0.5459647  0.5392702  0.53078914 0.49730566 0.4728824\n",
      "  0.461697   0.4546253  0.44609424 0.44507095]\n",
      " [0.99999994 0.49486718 0.45559788 0.45355242 0.39665496 0.36792052\n",
      "  0.32190388 0.3164804  0.30015716 0.29482713]\n",
      " [1.         0.3627315  0.35473233 0.34956825 0.32487544 0.3231224\n",
      "  0.321174   0.31687552 0.31625968 0.31568512]\n",
      " [1.0000001  0.5602732  0.50161195 0.49253085 0.4567728  0.43975207\n",
      "  0.43955243 0.43845576 0.43569523 0.42266226]\n",
      " [1.0000001  0.4411899  0.42892897 0.42879817 0.38495332 0.3678875\n",
      "  0.3664012  0.36023286 0.35649806 0.34881344]\n",
      " [1.         0.49179617 0.45746213 0.4333067  0.42787465 0.4221988\n",
      "  0.4182676  0.4089809  0.40249717 0.39649495]\n",
      " [1.0000001  0.41919076 0.37638593 0.3681253  0.35892776 0.35147664\n",
      "  0.3459133  0.3442192  0.3171566  0.31457284]\n",
      " [1.         0.44532177 0.40867501 0.4008432  0.36277956 0.36033776\n",
      "  0.34211183 0.34135386 0.33943984 0.3046336 ]\n",
      " [1.         0.5836266  0.54674673 0.5420593  0.51029176 0.41921002\n",
      "  0.40976003 0.40929514 0.40706173 0.4067574 ]\n",
      " [1.0000001  0.5551215  0.5511094  0.5207318  0.51871306 0.50526834\n",
      "  0.49462038 0.49253085 0.48287892 0.4796624 ]\n",
      " [1.0000001  0.54191345 0.5226192  0.5128911  0.47578782 0.45198363\n",
      "  0.44362932 0.43326837 0.399062   0.3936708 ]\n",
      " [1.0000001  0.389197   0.36890095 0.36023808 0.33994493 0.3231224\n",
      "  0.3157434  0.294349   0.29185715 0.28991362]\n",
      " [1.0000001  0.50702024 0.3875077  0.38060358 0.3529838  0.333989\n",
      "  0.30364248 0.30211565 0.2972497  0.29672426]\n",
      " [1.         0.6463918  0.578312   0.5503524  0.54190403 0.5291211\n",
      "  0.49825162 0.49730566 0.44573516 0.44362932]\n",
      " [1.         0.40499228 0.34719187 0.34395984 0.34277752 0.3303859\n",
      "  0.32557613 0.32190388 0.3182436  0.3148648 ]\n",
      " [0.99999994 0.64894146 0.6470904  0.6127438  0.4545316  0.40250263\n",
      "  0.39665496 0.34719187 0.3318601  0.32917613]\n",
      " [1.0000001  0.58344626 0.5523887  0.5163482  0.5029092  0.47221154\n",
      "  0.43838722 0.4367454  0.43513498 0.4092562 ]\n",
      " [0.99999994 0.69470364 0.55931973 0.5558753  0.55208665 0.52973974\n",
      "  0.49179617 0.47221154 0.47003874 0.4546253 ]\n",
      " [1.0000001  0.4575383  0.44407934 0.4226415  0.4183391  0.40704536\n",
      "  0.40678346 0.40250263 0.39901924 0.37700388]\n",
      " [1.         0.59814507 0.55096763 0.5029092  0.44508472 0.41643614\n",
      "  0.39490896 0.38997313 0.37623334 0.37566137]\n",
      " [1.0000001  0.43774587 0.3936708  0.3934961  0.38539195 0.36845744\n",
      "  0.36503288 0.35917243 0.3515798  0.34876326]\n",
      " [1.         0.42182285 0.41062602 0.40751404 0.38406068 0.38139382\n",
      "  0.37239423 0.36819607 0.36318532 0.35360226]\n",
      " [1.         0.52970946 0.51029176 0.4779844  0.45051512 0.4378347\n",
      "  0.43712327 0.4226415  0.41030505 0.40867501]\n",
      " [1.         0.7342477  0.59814507 0.5901313  0.578312   0.5523887\n",
      "  0.5511094  0.5459647  0.528228   0.5168169 ]\n",
      " [1.0000001  0.7237625  0.37310603 0.35877806 0.35607326 0.35553515\n",
      "  0.35222062 0.35055953 0.34861618 0.3452758 ]\n",
      " [1.0000002  0.7402782  0.7336303  0.6470904  0.528994   0.45559788\n",
      "  0.40499228 0.38060358 0.35904452 0.33679044]\n",
      " [1.0000001  0.50526834 0.46435747 0.44532177 0.4378347  0.43055126\n",
      "  0.4294215  0.4183391  0.38213557 0.377654  ]]\n",
      "CPU times: user 685 ms, sys: 30.5 ms, total: 715 ms\n",
      "Wall time: 328 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "fractal_dimensions = calculate_fractal_value(normalized_embeddings,5,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fractal Dimension: [2.321928094887362, 2.321928094887362, 2.321928094887362, 0.0, 0.0, 2.321928094887362, 1.5849625007211563, 1.0, 0.0, 1.5849625007211563, 1.0, 1.5849625007211563, 2.321928094887362, 1.0, 1.0, 1.5849625007211563, 2.584962500721156, 2.807354922057604, 0.0, 1.0, 1.0, 2.807354922057604, 0.0, 1.0, 2.584962500721156, 0.0, 0.0, 0.0, 2.0, 1.5849625007211563, 3.3219280948873626, 0.0, 1.5849625007211563, 1.0, 0.0, 1.0, 1.5849625007211563, 0.0, 1.0, 0.0, 1.0, 1.0, 3.0, 1.0, 0.0, 1.5849625007211563, 1.5849625007211563, 0.0, 0.0, 2.321928094887362, 1.0, 1.0, 2.807354922057604, 1.5849625007211563, 1.0, 2.0, 0.0, 1.0, 2.0, 0.0, 2.0, 2.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.5849625007211563, 1.0, 1.5849625007211563, 2.584962500721156, 2.0, 0.0, 0.0, 1.5849625007211563, 0.0, 0.0, 0.0, 0.0, 2.321928094887362, 2.584962500721156, 2.0, 0.0, 1.0, 2.584962500721156, 0.0, 2.0, 2.321928094887362, 2.584962500721156, 0.0, 2.0, 0.0, 0.0, 1.5849625007211563, 3.3219280948873626, 1.0, 2.321928094887362, 1.0]\n"
     ]
    }
   ],
   "source": [
    "print(\"Fractal Dimension:\", fractal_dimensions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Fractal_dimension_non_polysemous_words_cosine_100_5_10', 'w') as f:\n",
    "    for dimension in fractal_dimensions:\n",
    "        f.write(str(dimension) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98\n"
     ]
    }
   ],
   "source": [
    "print(len(open('Fractal_dimension_non_polysemous_words_cosine_100_5_10', 'r').readlines()))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
